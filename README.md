# Text-Classification-using-22-DL-ML-Models
 An extensive question-answer classification project consisting of dataset fetching, pre-processing, training 22 ML and NN/DL models, and evaluating them. 


This was a self-taught NLP project where I explored different word representation techniques, including Bag of Words (BoW), TF-IDF, GloVe, and Skip-gram, to convert unstructured text data into meaningful numerical features. These features are then used to train and evaluate a suite of models on a large dataset (250,000 rows), ranging from traditional machine learning algorithms like Random Forest, Logistic Regression, and Naive Bayes to more advanced deep learning architectures such as Deep Neural Networks (DNN), Simple RNNs, LSTMs, GRUs, and their bidirectional variants.
